Developments in Security, Virtual Reality, Quantum Computing, and More

January 4, 2024

More large language models. Always more large language models. Will the new year be any different? But there is a difference in this month’s AI news: there’s an emphasis on tools that make it easy for users to use models. Whether it’s just tweaking a URL so you can ask questions of a paper on arXiv or using LLamafile to run a model on your laptop (make sure you have a lot of memory!) or using the Notebook Language Model to query your own documents, AI is becoming widely accessible—and not just a toy with a web interface.

## Artificial Intelligence

- Adding talk2 to the start of any arXiv URL (e.g., talk2arxiv.org) loads the paper into an AI chat application so you can talk to it. This is a very clever [application of the RAG pattern](https://github.com/evanhu1/talk2arxiv).
- Google’s Autonomous Vehicle startup, Waymo, has [reported](https://arstechnica.com/cars/2023/12/human-drivers-crash-a-lot-more-than-waymos-software-data-shows/) a total of three minor injuries to humans in over 7 million miles of driving. This is clearly not Tesla, not Uber, not Cruise.
- Google’s DeepMind has used a large language model to [solve](https://www.technologyreview.com/2023/12/14/1085318/google-deepmind-large-language-model-solve-unsolvable-math-problem-cap-set/) a previously unsolved [problem](https://www.nature.com/articles/s41586-023-06924-6) in mathematics. This is arguably the first time a language model has created information that didn’t previously exist.
- The creator of [llamafile](https://github.com/Mozilla-Ocho/llamafile) has offered a set of [one-line bash scripts](https://justine.lol/oneliners/) for laptop-powered AI.
- Microsoft has [released](https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/) a small language model named Phi-2. Phi-2 is a 2.7B parameter model that has been trained extensively on “[textbook-quality data](https://www.microsoft.com/en-us/research/publication/textbooks-are-all-you-need/).” Without naming names, they claim performance superior to Llama 2.
- Claude, Anthropic’s large language model, [can be used in Google Sheets](https://docs.anthropic.com/claude/docs/using-claude-for-sheets) via a browser extension.
- The [Notebook Language Model](https://notebooklm.google.com/?pli=1) is a RAG implementation designed for individuals. It is a Google notebook (similar to Colab or Jupyter) that allows you to upload documents and then ask questions about those documents.
- The European Union is about to [pass its AI Act](https://www.technologyreview.com/2023/12/11/1084942/five-things-you-need-to-know-about-the-eus-new-ai-act/), which will be the world’s most significant attempt to [regulate](https://www.europarl.europa.eu/news/en/press-room/20231206IPR15699/artificial-intelligence-act-deal-on-comprehensive-rules-for-trustworthy-ai) artificial intelligence.
- Mistral has [released](https://mistral.ai/news/mixtral-of-experts/) [Mixtral](https://huggingface.co/docs/transformers/model_doc/mixtral) 8x7B, a mixture-of-experts model in which the model first determines which of eight sets of 7 billion parameters will generate the best response to a prompt. The results compare well to Llama 2. Mistral 7B and Mixtral can be run with [Llamafile](https://github.com/Mozilla-Ocho/llamafile).
- Meta has [announced](https://ai.meta.com/blog/purple-llama-open-trust-safety-generative-ai/) Purple Llama, a project around trust and safety for large language models. They have released a set of benchmarks for evaluating model safety, along with a classifier for filtering unsafe input (prompts) and model output.
- The [Switch Kit](https://postgresml.org/blog/introducing-the-openai-switch-kit-move-from-closed-to-open-source-ai-in-minutes) is an open source software development kit that allows you to replace OpenAI with an open source language model easily.
- Google has [announced](https://deepmind.google/technologies/gemini/#build-with-gemini) that its multimodal Gemini AI model is available to software developers via their AI Studio and Vertex AI.
- [Progressive upscaling](https://thenextweb.com/news/new-ai-tool-democratised-image-generation) is a technique for starting with a low-resolution image and using AI to increase the resolution. It reduces the computational power needed to generate high-resolution images. It has been implemented as a plug-in to Stable Diffusion called [DemoFusion](https://arxiv.org/abs/2311.16973).
- The internet enabled mass surveillance, but that still leaves you with exabytes of data to analyze. According to Bruce Schneier, AI’s ability to analyze and draw conclusions from that data enables “[mass spying](https://www.schneier.com/blog/archives/2023/12/the-internet-enabled-mass-surveillance-ai-will-enable-mass-spying.html).”
- A group of over 50 organizations, including Meta, IBM, and Hugging Face, has [formed the AI Alliance](https://9to5mac.com/2023/12/05/ai-alliance/) to focus on the development of open source models.
- DeepMind has built an AI system that demonstrates [social learning](https://techxplore.com/news/2023-12-deepmind-ai-social-capabilities.html): the ability to learn how to solve a problem by observing an expert.
- Are neural networks the only way to build artificial intelligence? [Hivekit](https://hivekit.io/blog/building-ai-without-a-neural-network/) is building tools for a distributed spatial rules engine that can provide the communications layer for hives, swarms, and colonies.
- The proliferation of AI testing tools continues with [Gaia](https://techxplore.com/news/2023-12-ai-gaia-benchmark-tool-general.html), a benchmark suite intended to determine whether AI systems are, indeed, intelligent. The benchmark consists of a set of questions that are easy for humans to answer but difficult for computers.
- Meta has just published a suite of multilingual spoken language models called [Seamless](https://ai.meta.com/research/seamless-communication/). The models are capable of near real-time translation and claim to be more faithful to natural human expression.
- In an experiment simulating a stock market, a stock-trading [AI system engaged in “insider trading”](https://www.schneier.com/blog/archives/2023/12/ai-decides-to-engage-in-insider-trading.html) after being put under pressure to show greater returns and receiving “tips” from company “employees.”
- What’s the best way to run a large language model on your laptop?  Simon Willison [recommends](https://simonwillison.net/2023/Nov/29/llamafile/) [llamafile](https://huggingface.co/jartine/llava-v1.5-7B-GGUF/blob/main/llamafile-server-0.1-llava-v1.5-7b-q4), which packages a model together with the weights as a single (large) executable that works on multiple operating systems.
- Further work on [extracting training data from ChatGPT](https://not-just-memorization.github.io/extracting-training-data-from-chatgpt.html), this time against the production model, shows that these systems may be opaque, but they aren’t quite “black boxes.”
- [Amazon Q](https://press.aboutamazon.com/2023/11/aws-announces-amazon-q-to-reimagine-the-future-of-work) is a new large language model that includes a chatbot and other tools to aid office workers. It can be customized by individual businesses that subscribe to the service so that it has access to their proprietary data.

---
Refs:
- https://learning.oreilly.com/library/view/radar-trends-to/9781098167912/ch01.html#artificial_intelligence